{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example SPARQL Queries to FNCT RDF Data\n",
    "\n",
    "In this Jupyter Notebook, FNCT RDF data is loaded into a local ('emulated') triple store using the owlready2 package. Having the triple store ready by having included a knowlegde graph containing FNCT data, this graph / triple store can be queried. \n",
    "\n",
    "Therefor, 2 example SPARQL queries are given. They can be used to count the number of triples in the graph which may be useful for consistency checks and to query for some important information on FNCT experiments. In particular, the query provided addresses the process ID, material, medium, time to failure and actual tensile stress of all instances of type \"FNCT\" in the loaded dataset / graph (FNCT tests included) since this may be the most relevant results of FNCT experiments.\n",
    "\n",
    "The working folder path has to be specified manually (see below, first cell): \n",
    "```python \n",
    "folder_path = r'Path_to_your_folder'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import owlready2 as or2\n",
    "from rdflib import Graph\n",
    "\n",
    "# Path to the folder regarded has to be defined that contains FNCT data\n",
    "# Caution: Exact folder to look for RDF data is set in the next lines - adapt if necessary\n",
    "folder_path = r'Path_to_your_folder'\n",
    "\n",
    "# Check if \"graph_data\" folder exists, otherwise stop reading in\n",
    "graph_data_folder = os.path.join(folder_path, \"graph_data\")\n",
    "if not os.path.exists(graph_data_folder):\n",
    "    print(f\"No graph data was found. '{graph_data_folder}' folder does not exist.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Create an empty graph\n",
    "entire_knowledge_graph = Graph()\n",
    "\n",
    "# Iterate over all RDF files in the given directory\n",
    "for filename in os.listdir(graph_data_folder):\n",
    "    if filename.endswith('.rdf'):\n",
    "        file_path_rdf = os.path.join(graph_data_folder, filename)\n",
    "        entire_knowledge_graph.parse(file_path_rdf, format='application/rdf+xml')\n",
    "\n",
    "# Serialize the combined graph to an output file to facilitate reading using owlready2\n",
    "output_file = os.path.join(graph_data_folder, \"entire_knowledge_graph.rdf\")\n",
    "entire_knowledge_graph.serialize(destination=output_file, format='application/rdf+xml')\n",
    "print(f\"Combined graph serialized to {output_file}\")\n",
    "\n",
    "\n",
    "link_data = f\"{graph_data_folder}\\\\entire_knowledge_graph.rdf\"\n",
    "link_core = \"https://materialdigital.github.io/core-ontology/ontology.rdf\" # Read in mid-level PMD Core Ontology (PMDco)\n",
    "link_ontoFNCT = \"https://markusschilling.github.io/ontoFNCT/ontology.rdf\" # Read in OntoFNCT\n",
    "\n",
    "triple_store = or2.World()\n",
    "triple_store.get_ontology(link_core).load() # https://w3id.org/pmd/co\n",
    "triple_store.get_ontology(link_ontoFNCT).load()  # https://w3id.org/ontofnct\n",
    "triple_store.get_ontology(link_data).load()  # Local data mapped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform inputs to IRIs.\n",
    "def to_iri(input):\n",
    "    try:\n",
    "        return input.iri\n",
    "    except:\n",
    "        pass\n",
    "    return input\n",
    "\n",
    "# Function to write the result of a SPARQL query into a (pandas) data frame.\n",
    "def sparql_result_to_df(res):\n",
    "    l = []\n",
    "    for row in res:\n",
    "        r = [ to_iri(item)  for item in row]\n",
    "        l.append(r)\n",
    "    return pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for the number of all triples in the loaded dataset / graph\n",
    "query=(\"\"\"\n",
    "    PREFIX pmdco: <https://w3id.org/pmd/co/>\n",
    "    PREFIX ontoFNCT: <https://w3id.org/ontofnct/>\n",
    "\n",
    "    SELECT (COUNT(?s) AS ?count)\n",
    "    WHERE {\n",
    "       ?s ?p ?o\n",
    "    }\n",
    "    \"\"\"\n",
    "    )\n",
    "# Create dataframe comprising the result of the SPARQL query.\n",
    "res = triple_store.sparql(query)\n",
    "data = sparql_result_to_df(res)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for the process ID, material, medium, time to failure and actual tensile stress of all instances of type \"FNCT\" in the loaded dataset / graph (FNCT tests included)\n",
    "query=(\"\"\"\n",
    "    PREFIX pmdco: <https://w3id.org/pmd/co/>\n",
    "    PREFIX ontoFNCT: <https://w3id.org/ontofnct/>\n",
    "\n",
    "    SELECT DISTINCT ?processID ?material ?medium ?timeToFailure ?stressMeasured\n",
    "    WHERE {\n",
    "    ?p a ontoFNCT:FullNotchCreepTest .\n",
    "    ?p pmdco:characteristic ?processIDInst .\n",
    "    ?processIDInst a pmdco:ProcessIdentifier .\n",
    "    ?processIDInst pmdco:value ?processID .\n",
    "    ?s a pmdco:Specimen .\n",
    "    ?p pmdco:input ?s .\n",
    "    ?s pmdco:characteristic ?materialDesc .\n",
    "    ?materialDesc a pmdco:materialDesignation .\n",
    "    ?materialDesc pmdco:value ?material .\n",
    "    ?p pmdco:participant ?mediumInst .\n",
    "    ?mediumInst a pmdco:Medium .\n",
    "    ?mediumInst pmdco:value ?medium .\n",
    "    ?p pmdco:output ?tfInst .\n",
    "    ?tfInst a ontoFNCT:TimeToFailure .\n",
    "    ?tfInst pmdco:value ?timeToFailure .\n",
    "    ?p pmdco:output ?stressInst .\n",
    "    ?stressInst a ontoFNCT:MeasuredTensileStress .\n",
    "    ?stressInst pmdco:value ?stressMeasured .\n",
    "    } ORDER BY ?material ?medium ?stressMeasured\n",
    "    \"\"\"\n",
    "    )\n",
    "    # Create dataframe comprising the result of the SPARQL query. This may take some time depending on the complexity of the query.\n",
    "res = triple_store.sparql(query)\n",
    "data = sparql_result_to_df(res)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
